{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8737f7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76dfa62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_over_union(box_preds, box_labels, box_format=\"midpoint\"):\n",
    "    \"\"\"\n",
    "    parameters:\n",
    "        boxes_preds (tensor): Predictions of Bounding Boxes (BATCH_SIZE, 4)\n",
    "        boxes_labels (tensor): Correct Labels of Boxes (BATCH_SIZE, 4)\n",
    "        box_format (str): midpoint/corners, if boxes (x,y,w,h) or (x1,y1,x2,y2)\n",
    "    \n",
    "    returns:\n",
    "        tensor: intersection over union for all examples\n",
    "    \"\"\"\n",
    "    if box_format == 'midpoint':\n",
    "        box1_x1 = box_preds[..., 0:1] - box_preds[..., 2:3]/2\n",
    "        box1_x2 = box_preds[..., 0:1] + box_preds[..., 2:3]/2\n",
    "        box1_y1 = box_preds[..., 1:2] - box_preds[..., 3:4]/2\n",
    "        box1_y2 = box_preds[..., 1:2] + box_preds[..., 3:4]/2\n",
    "        \n",
    "        box2_x1 = box_labels[..., 0:1] - box_preds[..., 2:3]/2\n",
    "        box2_x2 = box_labels[..., 0:1] + box_preds[..., 2:3]/2\n",
    "        box2_y1 = box_labels[..., 1:2] - box_preds[..., 3:4]/2\n",
    "        box2_y2 = box_labels[..., 1:2] + box_preds[..., 3:4]/2\n",
    "        \n",
    "    elif box_format == 'corners':\n",
    "        box1_x1 = box_preds[..., 0:1]\n",
    "        box1_x2 = box_preds[..., 2:3]\n",
    "        box1_y1 = box_preds[..., 1:2]\n",
    "        box1_y2 = box_preds[..., 3:4]\n",
    "        \n",
    "        box2_x1 = box_labels[..., 0:1]\n",
    "        box2_x2 = box_labels[..., 2:3]\n",
    "        box2_y1 = box_labels[..., 1:2]\n",
    "        box2_y2 = box_labels[..., 3:4]           \n",
    "        \n",
    "    x1 = torch.max(box1_x1, box2_x1)\n",
    "\n",
    "    x2 = torch.min(box1_x2, box2_x2)\n",
    "    y1 = torch.max(box1_y1, box2_y1)\n",
    "    y2 = torch.min(box1_y2, box2_y2)\n",
    "    \n",
    "    intersection = (x2-x1).clamp(0)*(y2-y1).clamp(0)\n",
    "    box1_area = abs((box1_x2-box1_x1)*(box1_y2-box1_y1))\n",
    "    box2_area = abs((box2_x2-box2_x1)*(box2_y2-box2_y1))\n",
    "    union = box1_area + box2_area -intersection\n",
    "    \n",
    "    return intersection/union+1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1ce7366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 7, 7, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box_preds = torch.randn(4,7,7,4)\n",
    "box_labels= torch.randn(4,7,7,4)\n",
    "intersection_over_union(box_preds, box_labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17bb5c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# from pathlib import Path\n",
    "# import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92564ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source = Path.cwd()/'labels.zip'\n",
    "# extract_folder = Path.cwd().parent/'labels_test'\n",
    "# extract_folder.mkdir(parents=True, exist_ok=True)\n",
    "# with zipfile.ZipFile(source, mode='r') as zip_ref:\n",
    "#     zip_ref.extractall(extract_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b75ae1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source = Path.cwd()/'labels.zip'\n",
    "# extract_folder = Path.cwd().parent/'labels_test'\n",
    "# extract_folder.mkdir(parents=True, exist_ok=True)\n",
    "# shutil.unpack_archive(source, extract_folder, format='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64e3581b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_supression(bboxes, iou_threshold, threshold, box_format=\"corners\"):\n",
    "    \"\"\"\n",
    "    does non max supression to given boxes\n",
    "    Parameters:\n",
    "        bboxes(list): list of lists containing all bboxes specified as\n",
    "        [class_pred, probablity, x1, y1, x2, y2]\n",
    "        iou_threshold (float): where predicted bboxes i correct\n",
    "        threshold (float):  threshold to remove predicted bboxes (independent of IoU) \n",
    "        box_format (str): midpoint or corners used to specify bboxes\n",
    "    \n",
    "    Returns:\n",
    "        list: bboxes after performing nms\n",
    "    \"\"\"\n",
    "    \n",
    "    assert type(bboxes) == list\n",
    "    \n",
    "    bboxes = [box for box in bboxes if box[1] > threshold]\n",
    "    bboxes = sorted(bboxes, key= lambda x: x[1], reverse=True)\n",
    "    bboxes_after_nms = []\n",
    "    \n",
    "    while bboxes:\n",
    "        chosen_box = bboxes.pop(0)\n",
    "        bboxes = [\n",
    "            box\n",
    "            for box in bboxes\n",
    "            if box[0] != chosen_box[0]\n",
    "            or intersection_over_union(\n",
    "                torch.tensor(chosen_box[2:]),\n",
    "                torch.tensor(box[2:]),\n",
    "                box_format=box_format\n",
    "            ) < iou_threshold        \n",
    "            \n",
    "        ]\n",
    "        \n",
    "        bboxes_after_nms.append(chosen_box)\n",
    "        \n",
    "    return bboxes_after_nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb58d075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_avg_precision(pred_boxes, truth_boxes, iou_threshold=0.5, box_format=\"midpoint\", num_classes=20):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        pred_boxes (list): list of lists containing all bboxes with each bboxes\n",
    "        specified as [train_idx, class_prediction, prob_score, x1, y1, x2, y2] #train_idx=which image\n",
    "        true_boxes (list): Similar as pred_boxes except all the correct ones \n",
    "        iou_threshold (float): threshold where predicted bboxes is correct\n",
    "        box_format (str): \"midpoint\" or \"corners\" used to specify bboxes\n",
    "        num_classes (int): number of classes\n",
    "\n",
    "    \n",
    "    Returns:\n",
    "        float: mAP value across all classes given a specific IoU threshold \n",
    "    \"\"\"\n",
    "    epsilon = 1e-6\n",
    "    average_precision = []\n",
    "    \n",
    "\n",
    "    for i in range(num_classes):\n",
    "        detections = []\n",
    "        ground_truths = []\n",
    "        \n",
    "        # Go through all predictions and targets,\n",
    "        # and only add the ones that belong to the\n",
    "        # current class i        \n",
    "        for detection in pred_boxes:\n",
    "            if detection[1] == i:\n",
    "                detections.append(detection)\n",
    "                \n",
    "        \n",
    "        for truth_box in truth_boxes:\n",
    "                if truth_box[1] == i:\n",
    "                    ground_truths.append(truth_box)\n",
    "                \n",
    "        # find the amount of bboxes for each training example\n",
    "        # Counter here finds how many ground truth bboxes we get\n",
    "        # for each training example, so let's say img 0 has 3,\n",
    "        # img 1 has 5 then we will obtain a dictionary with:\n",
    "        # amount_bboxes = {0:3, 1:5}       \n",
    "        bboxes_amount = Counter([i[0] for i in ground_truths])\n",
    "               \n",
    "        # We then go through each key, val in this dictionary\n",
    "        # and convert to the following (w.r.t same example):\n",
    "        # ammount_bboxes = {0:torch.tensor[0,0,0], 1:torch.tensor[0,0,0,0,0]}\n",
    "        bboxes_amount = {key:torch.zeros(val) for key, val in bboxes_amount.items()}\n",
    "            \n",
    "        # sort by box probabilities which is index 2\n",
    "        detections.sort(key=lambda x: x[2], reverse=True)\n",
    "        TP = torch.zeros(len(detections))\n",
    "        FP = torch.zeros(len(detections))\n",
    "        total_true_bboxes = len(ground_truths)\n",
    "        \n",
    "        # If none exists for this class then we can safely skip\n",
    "        if total_true_bboxes == 0:\n",
    "            continue\n",
    "        \n",
    "        for detection_idx, detection in enumerate(detections):\n",
    "            # Only take out the ground_truths that have the same\n",
    "            # training idx as detection\n",
    "            ground_truth_image = [\n",
    "                bbox\n",
    "                for bbox in ground_truths\n",
    "                if bbox[0] == detection[0] \n",
    "            ]\n",
    "            \n",
    "#             num_gts = len(ground_truth_image)  #debug this later\n",
    "            best_iou = 0\n",
    "            for idx, gt in enumerate(ground_truth_image):\n",
    "                iou = intersection_over_union(\n",
    "                    torch.tensor(detection[3:]),\n",
    "                    torch.tensor(gt[3:]),\n",
    "                    box_format=box_format\n",
    "                \n",
    "                )\n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_gt_idx = idx\n",
    "                \n",
    "            if best_iou > iou_threshold:\n",
    "                # only detect ground truth detection once\n",
    "                if bboxes_amount[detection[0]][best_gt_idx] == 0:\n",
    "                    TP[detection_idx] = 1\n",
    "                else:\n",
    "                    FP[detection_idx] = 1\n",
    "            \n",
    "            # if IOU is lower then the detection is a false positive\n",
    "            else:\n",
    "                FP[detection_idx] = 1\n",
    "            \n",
    "        tp_cumsum = torch.cumsum(TP, dim=0)\n",
    "        fp_cumsum = torch.cumsum(FP, dim=0)\n",
    "        \n",
    "        precisions = tp_cumsum / (tp_cumsum + fp_cumsum + epsilon)\n",
    "        recalls = tp_cumsum / (total_true_bboxes + epsilon)\n",
    "        \n",
    "        precisions = torch.cat((torch.tensor([1]), precisions))\n",
    "        recalls = torch.cat((torch.tensor([0]), recalls))\n",
    "        area = torch.trapz(precisions, recalls)\n",
    "        \n",
    "        average_precision.append(area)\n",
    "        \n",
    "    return sum(average_precision) / len(average_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d925a90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_boxes = [[0, 2, 0.6, 0.2, 0.4, 0.4, 0.6], [1, 1, 0.7, 0.2, 0.4, 0.4, 0.6]]\n",
    "# truth_boxes = [[0, 2, 0.5, 0.2, 0.4, 0.4, 0.6], [1, 2, 0.9, 0.2, 0.4, 0.4, 0.6],[1, 1, 0.8, 0.2, 0.4, 0.4, 0.6]]\n",
    "# a = mean_avg_precision(pred_boxes, truth_boxes)\n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e1bd756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_cell_boxes(predictions, s=7):\n",
    "    batch_size = predictions.shape[0]\n",
    "    predictions = predictions.to(\"cpu\")\n",
    "    predictions = predictions.reshape(batch_size, s, s, 30)\n",
    "    bboxes1 = predictions[..., 21:25]\n",
    "    bboxes2 = predictions[..., 26:30]\n",
    "    \n",
    "    class_pred = torch.argmax(predictions[..., :20], dim=-1).unsqueeze(-1)\n",
    "    best_prob = torch.max(predictions[..., 20:21], predictions[..., 25:26])\n",
    "    scores = torch.stack((predictions[..., 20:21], predictions[..., 25:26]), dim=0)\n",
    "    best_box = torch.argmax(scores,dim=0)\n",
    "    best_boxes = (1-best_box)*bboxes1 + best_box*bboxes2\n",
    "    \n",
    "    cell_indices = torch.arange(s).repeat(batch_size,s,1).unsqueeze(-1)\n",
    "    x = 1/s*(best_boxes[...,:1] + cell_indices)\n",
    "    y = 1/s*(best_boxes[...,1:2] + cell_indices.permute(0,2,1,3))\n",
    "    w_h = 1 / s * best_boxes[..., 2:4]\n",
    "    conv_boxes = torch.cat((x,y,w_h), dim=-1)\n",
    "    \n",
    "    pred_converted_boxes = torch.cat(\n",
    "        (class_pred, best_prob, conv_boxes), dim=-1\n",
    "    )\n",
    "    \n",
    "    return pred_converted_boxes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ef2b3a0f",
   "metadata": {},
   "source": [
    "import unittest\n",
    "\n",
    "preds = torch.randn(8,7,7, 30)\n",
    "class Test_utils(unittest.TestCase):\n",
    "    def test_convert_cell_boxes(self):\n",
    "        self.assertEqual(convert_cell_boxes(preds).shape, torch.Size([8, 7, 7, 6]))\n",
    "        \n",
    "# test_module = Test_utils()\n",
    "# test_module.test_convert_cell_boxes()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f780dfc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 7, 7, 6])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = torch.randn(8,7,7, 30)\n",
    "convert_cell_boxes(preds).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e59ef669",
   "metadata": {},
   "outputs": [],
   "source": [
    "##turn tensor matrixes to python lists\n",
    "def cellboxes_to_boxes(out, s=7):\n",
    "    \"\"\"\n",
    "        Returns:\n",
    "        tensor: torch.tensor() with size (batch_size, s*s, 6)\n",
    "    \"\"\"\n",
    "    batch_size = out.shape[0]\n",
    "    converted_pred  = convert_cell_boxes(out).reshape(batch_size, s*s, -1)\n",
    "    converted_pred[...,0] = converted_pred[...,0].long()\n",
    "    \n",
    "    all_bboxes = []\n",
    "    \n",
    "    for batch_idx in range(batch_size):\n",
    "        bboxes = []\n",
    "        \n",
    "        for bbox_idx in range(s*s):\n",
    "            bboxes.append([x.item() for x in converted_pred[batch_idx, bbox_idx, : ]])\n",
    "            \n",
    "        all_bboxes.append(bboxes)\n",
    "        \n",
    "    return all_bboxes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79960573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 49, 6])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = cellboxes_to_boxes(preds)\n",
    "torch.tensor(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "890f8f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bboxes(\n",
    "    loader,\n",
    "    model,\n",
    "    iou_threshold,\n",
    "    threshold,\n",
    "    pred_format=\"cells\",\n",
    "    box_format=\"midpoint\",\n",
    "    device=\"cuda\",\n",
    "    ):\n",
    "    all_pred_boxes = []\n",
    "    all_true_boxes = []\n",
    "    \n",
    "    model.eval()\n",
    "    train_idx = 0\n",
    "    \n",
    "    for batch_idx, (x, y) in enumerate(loader):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        with torch.inference_mode():\n",
    "            predictions = model(x)\n",
    "            \n",
    "        bboxes = cellboxes_to_boxes(predictions)\n",
    "        true_bboxes = cellboxes_to_boxes(y)\n",
    "        \n",
    "        batch_size = x.shape[0]\n",
    "        for idx in range(batch_size):\n",
    "            nms_boxes = non_max_supression(\n",
    "                bboxes[idx],\n",
    "                iou_threshold,\n",
    "                threshold,\n",
    "                box_format\n",
    "            )\n",
    "            \n",
    "            #if batch_idx == 0 and idx == 0:\n",
    "            #    plot_image(x[idx].permute(1,2,0).to(\"cpu\"), nms_boxes)\n",
    "            #    print(nms_boxe\n",
    "            \n",
    "            for nms_box in nms_boxes:\n",
    "                all_pred_boxes.append([train_idx] + nms_box)\n",
    "            \n",
    "            for box in true_bboxes[idx]:\n",
    "                # many will get converted to pred 0\n",
    "                if box[1] > threshold:\n",
    "                    all_true_boxes.append([train_idx] + box)\n",
    "                    \n",
    "            train_idx += 1\n",
    "            \n",
    "    model.train()\n",
    "            \n",
    "    return all_pred_boxes, all_true_boxes\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4532934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(image,bboxs):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
